{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","mount_file_id":"1UehKZgifIuMF3fug88L9CIeCcjGXbY9e","authorship_tag":"ABX9TyNg08i4VoONaGgfqWR9j/u7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RSeSgzy69RJK","executionInfo":{"status":"ok","timestamp":1678668602722,"user_tz":420,"elapsed":1010614,"user":{"displayName":"A SAL","userId":"12890107829430246221"}},"outputId":"fa8ca455-5533-4efe-dd4d-c8abf0bb116d"},"outputs":[{"output_type":"stream","name":"stdout","text":["(26709,)\n","Epoch 1/10\n","625/625 [==============================] - 109s 163ms/step - loss: 0.4509 - accuracy: 0.7737 - val_loss: 0.3995 - val_accuracy: 0.8150\n","Epoch 2/10\n","625/625 [==============================] - 101s 161ms/step - loss: 0.3659 - accuracy: 0.8300 - val_loss: 0.3903 - val_accuracy: 0.8205\n","Epoch 3/10\n","625/625 [==============================] - 101s 161ms/step - loss: 0.3460 - accuracy: 0.8440 - val_loss: 0.3797 - val_accuracy: 0.8265\n","Epoch 4/10\n","625/625 [==============================] - 100s 160ms/step - loss: 0.3268 - accuracy: 0.8564 - val_loss: 0.3718 - val_accuracy: 0.8335\n","Epoch 5/10\n","625/625 [==============================] - 101s 161ms/step - loss: 0.3170 - accuracy: 0.8593 - val_loss: 0.3802 - val_accuracy: 0.8280\n","Epoch 6/10\n","625/625 [==============================] - 100s 160ms/step - loss: 0.3074 - accuracy: 0.8640 - val_loss: 0.3720 - val_accuracy: 0.8275\n","Epoch 7/10\n","625/625 [==============================] - 99s 159ms/step - loss: 0.3012 - accuracy: 0.8674 - val_loss: 0.3744 - val_accuracy: 0.8335\n","Epoch 8/10\n","625/625 [==============================] - 100s 160ms/step - loss: 0.2938 - accuracy: 0.8716 - val_loss: 0.3812 - val_accuracy: 0.8315\n","Epoch 9/10\n","625/625 [==============================] - 100s 159ms/step - loss: 0.2900 - accuracy: 0.8729 - val_loss: 0.3754 - val_accuracy: 0.8290\n","Epoch 10/10\n","625/625 [==============================] - 99s 158ms/step - loss: 0.2847 - accuracy: 0.8752 - val_loss: 0.3774 - val_accuracy: 0.8300\n"]}],"source":["# ======================================================================\n","# There are 5 questions in this exam with increasing difficulty from 1-5.\n","# Please note that the weight of the grade for the question is relative\n","# to its difficulty. So your Category 1 question will score significantly\n","# less than your Category 5 question.\n","#\n","# Don't use lambda layers in your model.\n","# You do not need them to solve the question.\n","# Lambda layers are not supported by the grading infrastructure.\n","#\n","# You must use the Submit and Test button to submit your model\n","# at least once in this category before you finally submit your exam,\n","# otherwise you will score zero for this category.\n","# ======================================================================\n","#\n","# NLP QUESTION\n","#\n","# Build and train a classifier for the sarcasm dataset.\n","# The classifier should have a final layer with 1 neuron activated by sigmoid as shown.\n","# It will be tested against a number of sentences that the network hasn't previously seen\n","# and you will be scored on whether sarcasm was correctly detected in those sentences.\n","\n","import json\n","import tensorflow as tf\n","import numpy as np\n","import urllib\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import pandas as pd\n","\n","def solution_model():\n","    url = 'https://storage.googleapis.com/download.tensorflow.org/data/sarcasm.json'\n","    urllib.request.urlretrieve(url, 'sarcasm.json')\n","\n","\n","    # DO NOT CHANGE THIS CODE OR THE TESTS MAY NOT WORK\n","    vocab_size = 1000\n","    embedding_dim = 16\n","    max_length = 120\n","    trunc_type='post'\n","    padding_type='post'\n","    oov_tok = \"<OOV>\"\n","    training_size = 20000\n","    val_test_split_index = 22000\n","\n","    sentences = []\n","    labels = []\n","\n","    loaded = json.loads(open('/content/sarcasm.json', \"r\").read())\n","    for line in loaded:\n","      sentences.append(str(line['headline']))\n","      labels.append(int(line['is_sarcastic']))\n","      \n","    labels = np.array(labels)\n","    print(labels.shape)\n","\n","\n","    tokenizer = Tokenizer(\n","        num_words=vocab_size,\n","        oov_token=oov_tok\n","    )\n","    \n","    tokenizer.fit_on_texts(sentences)\n","    sentences = tokenizer.texts_to_sequences(sentences)\n","    # sentences = tokenizer.texts_to_matrix(sentences, mode='tfidf')\n","    sentences = pad_sequences(sentences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n","\n","    train_sentences = sentences[:training_size]\n","    train_labels = labels[:training_size]\n","\n","    val_sentences = sentences[training_size:val_test_split_index]\n","    val_labels = labels[training_size:val_test_split_index]\n","\n","    test_sentences = sentences[val_test_split_index:]\n","    test_labels = labels[val_test_split_index:]\n","\n","\n","\n","\n","    model = tf.keras.Sequential([\n","    # YOUR CODE HERE. KEEP THIS OUTPUT LAYER INTACT OR TESTS MAY FAIL\n","        tf.keras.layers.Embedding(\n","            input_dim=vocab_size, # set input shape\n","            output_dim=embedding_dim, # set size of embedding vector\n","            embeddings_initializer=\"uniform\", # default, intialize randomly\n","            input_length=max_length, # how long is each input\n","        ),\n","        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, recurrent_dropout = 0.3 , dropout = 0.3, return_sequences = True)),\n","        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, recurrent_dropout = 0.1 , dropout = 0.1)),\n","        tf.keras.layers.Dense(512, activation = \"relu\"),\n","        tf.keras.layers.Dense(1, activation='sigmoid')\n","    ])\n","\n","    # Compile model\n","    model.compile(loss=\"binary_crossentropy\",\n","                    optimizer=tf.keras.optimizers.Adam(),\n","                    metrics=[\"accuracy\"])\n","\n","    # Fit model\n","    model.fit(train_sentences,\n","        train_labels,\n","        epochs=10,\n","        validation_data=(val_sentences, val_labels)\n","    )\n","\n","    return model\n","\n","\n","# Note that you'll need to save your model as a .h5 like this.\n","# When you press the Submit and Test button, your saved .h5 model will\n","# be sent to the testing infrastructure for scoring\n","# and the score will be returned to you.\n","if __name__ == '__main__':\n","\n","    solution_model()\n","    # model = solution_model()\n","    # model.save(\"mymodel.h5\")\n"]},{"cell_type":"code","source":["#release\n","# ==============================================================================\n","# There are 5 questions in this exam with increasing difficulty from 1-5.\n","# Please note that the weight of the grade for the question is relative to its\n","# difficulty. So your Category 1 question will score significantly less than\n","# your Category 5 question.\n","#\n","# WARNING: Do not use lambda layers in your model, they are not supported\n","# on the grading infrastructure. You do not need them to solve the question.\n","#\n","# WARNING: If you are using the GRU layer, it is advised not to use the\n","# recurrent_dropout argument (you can alternatively set it to 0),\n","# since it has not been implemented in the cuDNN kernel and may\n","# result in much longer training times.\n","#\n","# WARNING: Input and output shape requirements are laid down in the section \n","# 'INSTRUCTIONS' below and also reiterated in code comments. \n","# Please read them thoroughly. After submitting the trained model for scoring, \n","# if you are receiving a score of 0 or an error, please recheck the input and \n","# output shapes of the model to see if it exactly matches our requirements. \n","# Grading infrastrcuture is very strict about the shape requirements. Most common \n","# issues occur when the shapes are not matching our expectations.\n","#\n","# TIP: You can print the output of model.summary() to review the model\n","# architecture, input and output shapes of each layer.\n","# If you have made sure that you have matched the shape requirements\n","# and all the other instructions we have laid down, and still\n","# receive a bad score, you must work on improving your model.\n","#\n","# You must use the Submit and Test button to submit your model\n","# at least once in this category before you finally submit your exam,\n","# otherwise you will score zero for this category.\n","# ==============================================================================\n","#\n","# TIME SERIES QUESTION\n","#\n","# Build and train a neural network to predict the time indexed variable of\n","# the univariate US diesel prices (On - Highway) All types for the period of\n","# 1994 - 2021.\n","# Using a window of past 10 observations of 1 feature , train the model\n","# to predict the next 10 observations of that feature.\n","#\n","# ==============================================================================\n","#\n","# ABOUT THE DATASET\n","#\n","# Original Source:\n","# https://www.eia.gov/dnav/pet/pet_pri_gnd_dcus_nus_w.htm#\n","#\n","# For the purpose of the examination we have used the Diesel (On - Highway) -\n","# All Types time series data for the period of 1994 - 2021 from the\n","# aforementioned link. The dataset has 1 time indexed feature.\n","# We have provided a cleaned version of the data.\n","#\n","# ==============================================================================\n","#\n","# INSTRUCTIONS\n","#\n","# Complete the code in following functions:\n","# 1. solution_model()\n","#\n","# You may receive a score of 0 or your code will fail to be graded if the \n","# following criteria are not met:\n","#\n","# 1. Model input shape must be (BATCH_SIZE, N_PAST = 10, N_FEATURES = 1),\n","#    since the testing infrastructure expects a window of past N_PAST = 10\n","#    observations of the 1 feature to predict the next N_FUTURE = 10\n","#    observations of the same feature.\n","#\n","# 2. Model output shape must be (BATCH_SIZE, N_FUTURE = 10, N_FEATURES = 1)\n","#\n","# 3. The last layer of your model must be a Dense layer with 1 neuron since\n","#    the model is expected to predict observations of 1 feature.\n","#\n","# 4. Don't change the values of the following constants:\n","#    SPLIT_TIME, N_FEATURES, BATCH_SIZE, N_PAST, N_FUTURE, SHIFT, in\n","#    solution_model() (See code for additional note on BATCH_SIZE).\n","#\n","# 5. Code for normalizing the data is provided - don't change it.\n","#    Changing the normalizing code will affect your score.\n","#\n","# 6. Code for converting the dataset into windows is provided - don't change it.\n","#    Changing the windowing code will affect your score.\n","#\n","# 7. Code for setting the seed is provided - don't change it.\n","#\n","# Make sure that the model architecture and input, output shapes match our\n","# requirements by printing model.summary() and reviewing its output.\n","#\n","# HINT: If you follow all the rules mentioned above and throughout this\n","# question while training your neural network, there is a possibility that a\n","# validation MAE of approximately 0.02 or less on the normalized validation\n","# dataset may fetch you top marks.\n","\n","\n","import pandas as pd\n","import tensorflow as tf\n","\n","\n","# This function normalizes the dataset using min max scaling.\n","# DO NOT CHANGE THIS CODE\n","def normalize_series(data, min, max):\n","    data = data - min\n","    data = data / max\n","    return data\n","\n","\n","# This function is used to map the time series dataset into windows of\n","# features and respective targets, to prepare it for training and validation.\n","# The first element of the first window will be the first element of\n","# the dataset.\n","#\n","# Consecutive windows are constructed by shifting the starting position\n","# of the first window forward, one at a time (indicated by shift=1).\n","#\n","# For a window of n_past number of observations of the time\n","# indexed variable in the dataset, the target for the window is the next\n","# n_future number of observations of the variable, after the\n","# end of the window.\n","\n","# DO NOT CHANGE THIS.\n","def windowed_dataset(series, batch_size, n_past=10, n_future=10, shift=1):\n","    ds = tf.data.Dataset.from_tensor_slices(series)\n","    ds = ds.window(size=n_past + n_future, shift=shift, drop_remainder=True)\n","    ds = ds.flat_map(lambda w: w.batch(n_past + n_future))\n","    ds = ds.map(lambda w: (w[:n_past], w[n_past:]))\n","    return ds.batch(batch_size).prefetch(1)\n","\n","\n","# This function loads the data from the CSV file, normalizes the data and\n","# splits the dataset into train and validation data. It also uses\n","# windowed_dataset() to split the data into windows of observations and\n","# targets. Finally it defines, compiles and trains a neural network. This\n","# function returns the final trained model.\n","\n","# COMPLETE THE CODE IN THIS FUNCTION\n","def solution_model():\n","    # DO NOT CHANGE THIS CODE\n","    # Reads the dataset.\n","    df = pd.read_csv('/content/drive/MyDrive/ethereum_all_time.csv')\n","\n","    df = pd.DataFrame(\n","        data={\n","            'Date': pd.to_datetime(df['timestamp']).dt.strftime('%Y-%m-%d'),\n","            'Price': df['close']\n","        }\n","\n","    )\n","    print(df)\n","\n","    # # Number of features in the dataset. We use all features as predictors to\n","    # # predict all features of future time steps.\n","    # N_FEATURES = len(df.columns) # DO NOT CHANGE THIS\n","\n","    # # Normalizes the data\n","    # data = df.values\n","    # data = normalize_series(data, data.min(axis=0), data.max(axis=0))\n","\n","    # # Splits the data into training and validation sets.\n","    # SPLIT_TIME = int(len(data) * 0.8) # DO NOT CHANGE THIS\n","    # x_train = data[:SPLIT_TIME]\n","    # x_valid = data[SPLIT_TIME:]\n","\n","    # # DO NOT CHANGE THIS CODE\n","    # tf.keras.backend.clear_session()\n","    # tf.random.set_seed(42)\n","\n","    # # DO NOT CHANGE BATCH_SIZE IF YOU ARE USING STATEFUL LSTM/RNN/GRU.\n","    # # THE TEST WILL FAIL TO GRADE YOUR SCORE IN SUCH CASES.\n","    # # In other cases, it is advised not to change the batch size since it\n","    # # might affect your final scores. While setting it to a lower size\n","    # # might not do any harm, higher sizes might affect your scores.\n","    # BATCH_SIZE = 32  # ADVISED NOT TO CHANGE THIS\n","\n","    # # DO NOT CHANGE N_PAST, N_FUTURE, SHIFT. The tests will fail to run\n","    # # on the server.\n","    # # Number of past time steps based on which future observations should be\n","    # # predicted\n","    # N_PAST = 10  # DO NOT CHANGE THIS\n","\n","    # # Number of future time steps which are to be predicted.\n","    # N_FUTURE = 10  # DO NOT CHANGE THIS\n","\n","    # # By how many positions the window slides to create a new window\n","    # # of observations.\n","    # SHIFT = 1  # DO NOT CHANGE THIS\n","\n","    # # Code to create windowed train and validation datasets.\n","    # train_set = windowed_dataset(series=x_train, batch_size=BATCH_SIZE,\n","    #                              n_past=N_PAST, n_future=N_FUTURE,\n","    #                              shift=SHIFT)\n","    # valid_set = windowed_dataset(series=x_valid, batch_size=BATCH_SIZE,\n","    #                              n_past=N_PAST, n_future=N_FUTURE,\n","    #                              shift=SHIFT)\n","\n","    # # Code to define your model.\n","    # model = tf.keras.models.Sequential([\n","\n","    #     # ADD YOUR LAYERS HERE.\n","\n","    #     # If you don't follow the instructions in the following comments,\n","    #     # tests will fail to grade your code:\n","    #     # The input layer of your model must have an input shape of:\n","    #     # (BATCH_SIZE, N_PAST = 10, N_FEATURES = 1)\n","    #     # The model must have an output shape of:\n","    #     # (BATCH_SIZE, N_FUTURE = 10, N_FEATURES = 1).\n","    #     # Make sure that there are N_FEATURES = 1 neurons in the final dense\n","    #     # layer since the model predicts 1 feature.\n","\n","    #     # HINT: Bidirectional LSTMs may help boost your score. This is only a\n","    #     # suggestion.\n","\n","    #     # WARNING: After submitting the trained model for scoring, if you are\n","    #     # receiving a score of 0 or an error, please recheck the input and \n","    #     # output shapes of the model to see if it exactly matches our requirements. \n","    #     # The grading infrastructure is very strict about the shape requirements. \n","    #     # Most common issues occur when the shapes are not matching our \n","    #     # expectations.\n","    #     #\n","    #     # TIP: You can print the output of model.summary() to review the model\n","    #     # architecture, input and output shapes of each layer.\n","    #     # If you have made sure that you have matched the shape requirements\n","    #     # and all the other instructions we have laid down, and still\n","    #     # receive a bad score, you must work on improving your model.\n","\n","    #     # WARNING: If you are using the GRU layer, it is advised not to use the\n","    #     # recurrent_dropout argument (you can alternatively set it to 0),\n","    #     # since it has not been implemented in the cuDNN kernel and may\n","    #     # result in much longer training times.\n","    #     tf.keras.layers.Dense(N_FEATURES)\n","    # ])\n","\n","    # # Code to train and compile the model\n","    # optimizer =  # YOUR CODE HERE\n","    # model.compile(\n","    #     # YOUR CODE HERE\n","    # )\n","    # model.fit(\n","    #     # YOUR CODE HERE\n","    # )\n","\n","    # return model\n","\n","\n","# Note that you'll need to save your model as a .h5 like this.\n","# When you press the Submit and Test button, your saved .h5 model will\n","# be sent to the testing infrastructure for scoring\n","# and the score will be returned to you.\n","\n","if __name__ == '__main__':\n","    solution_model()\n","    # model = solution_model()\n","    # model.save(\"mymodel.h5\")\n","\n","\n","# THIS CODE IS USED IN THE TESTER FOR FORECASTING. IF YOU WANT TO TEST YOUR MODEL\n","# BEFORE UPLOADING YOU CAN DO IT WITH THIS\n","\n","#def model_forecast(model, series, window_size, batch_size):\n","#    ds = tf.data.Dataset.from_tensor_slices(series)\n","#    ds = ds.window(window_size, shift=1, drop_remainder=True)\n","#    ds = ds.flat_map(lambda w: w.batch(window_size))\n","#    ds = ds.batch(batch_size, drop_remainder=True).prefetch(1)\n","#    forecast = model.predict(ds)\n","#    return forecast\n","\n","# PASS THE NORMALIZED data IN THE FOLLOWING CODE\n","\n","# rnn_forecast = model_forecast(model, data, N_PAST, BATCH_SIZE)\n","# rnn_forecast = rnn_forecast[SPLIT_TIME - N_PAST:-1, 0, 0]\n","\n","# x_valid = np.squeeze(x_valid[:rnn_forecast.shape[0]])\n","# result = tf.keras.metrics.mean_absolute_error(x_valid, rnn_forecast).numpy()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"McqE9xmhA_E2","executionInfo":{"status":"ok","timestamp":1678697727626,"user_tz":420,"elapsed":142,"user":{"displayName":"A SAL","userId":"12890107829430246221"}},"outputId":"a97d7719-f39a-4bd2-cb26-4f5d37436119"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["            Date               Price\n","0     1970-01-01           undefined\n","1     1970-01-01  1588.1286751747675\n","2     1970-01-01           undefined\n","3     1970-01-01  1482.0390874769444\n","4     1970-01-01           undefined\n","...          ...                 ...\n","3182  1970-01-01           undefined\n","3183  1970-01-01           undefined\n","3184  1970-01-01           undefined\n","3185  1970-01-01           undefined\n","3186  1970-01-01           undefined\n","\n","[3187 rows x 2 columns]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"N91hVCOPNXTq"},"execution_count":null,"outputs":[]}]}